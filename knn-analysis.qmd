---
title: "STAT 551 Final Project: KNN Analysis"
format: html
editor: source 
---
In this file, we will be using K-nearest neigbors analysis on the datasets to see if we can extract any relevant insights. 

```{r setup}
set.seed(3849)

library(tidyverse)
library(tidymodels)
library(readr)
library(ggplot2)
library(broom)
```

```{r}
MH <- read_csv(here::here("Student Mental health.csv"))
head(MH)
```

```{r}
MH_clean <- MH %>% 
  mutate(
    Gender = as.factor(`Choose your gender`),
    Course = as.factor(`What is your course?`),
    Year = as.factor(`Your current year of Study`),
    CGPA = as.factor(`What is your CGPA?`),  
    Marital_Status = as.factor(`Marital status`),
    Depression = as.factor(`Do you have Depression?`),
    Anxiety = as.factor(`Do you have Anxiety?`), 
    Panic_Attacks = as.factor(`Do you have Panic attack?`),
    Specialist_Treatment = as.factor(`Did you seek any specialist for a treatment?`)
  ) %>%
  select(-Timestamp)
```

```{r}
MH_clean <- MH_clean %>%
  mutate(
    CGPA = case_when(
      CGPA == "0 - 1.99" ~ 1,     
      CGPA == "2.00 - 2.49" ~ 2.25,  
      CGPA == "2.50 - 2.99" ~ 2.75,  
      CGPA == "3.00 - 3.49" ~ 3.25,  
      CGPA == "3.50 - 4.00" ~ 3.75, 
      TRUE ~ NA_real_               
    )
  )
```


```{r}
mh_recipe <- recipe(CGPA ~ Gender + Year + Marital_Status + Depression + Anxiety + 
                      Panic_Attacks + Specialist_Treatment, 
                    data = MH_clean) %>%
  step_dummy(all_nominal_predictors()) %>% 
  step_normalize(all_numeric_predictors())
```

```{r}
knn_mod_tune <- nearest_neighbor(neighbors = tune()) |>
  set_engine("kknn") |>
  set_mode("regression")
```

```{r}
knn_workflow <- workflow() %>%
  add_model(knn_mod_tune) %>%
  add_recipe(mh_recipe)

mh_cvs <- vfold_cv(MH_clean, v = 5, strata = CGPA)
```

```{r}
knn_grid <- grid_regular(neighbors(range = c(1, 20)), levels = 20)

set.seed(123)
knn_tune_results <- tune_grid(
  knn_workflow,
  resamples = mh_cvs,
  grid = knn_grid
)
```

```{r}
knn_tune_results |> 
  collect_metrics() |>
  filter(.metric == "rmse") |>
  slice_min(mean, n = 3)

knn_tune_results |> 
  collect_metrics() |>
  filter(.metric == "rsq") |>
  slice_max(mean, n = 3)
```
```{r}
knn_mod_best <- nearest_neighbor(neighbors = 2) |>
  set_mode("regression") |> 
  set_engine("kknn")
```

```{r}
best_workflow <- workflow() |>
  add_recipe(mh_recipe) |>
  add_model(knn_mod_best)

best_fit <- best_workflow |>
  fit(MH_clean) 

best_fit |> 
  extract_fit_parsnip()
```

```{r}
predictions <- predict(best_fit, new_data = MH_clean) %>%
  bind_cols(MH_clean)

regression_metrics <- predictions %>%
  metrics(truth = CGPA, estimate = .pred)

print(regression_metrics)
```

```{r}
predictions2 <- predictions %>%
  mutate(
    actual_bin = cut(CGPA, 
                     breaks = c(0, 2.00, 2.50, 3.00, 3.50, 4.00), 
                     labels = c("0 - 1.99", "2.00 - 2.49", "2.50 - 2.99", "3.00 - 3.49", "3.50 - 4.00"), 
                     include.lowest = TRUE),
    predicted_bin = cut(.pred, 
                        breaks = c(0, 2.00, 2.50, 3.00, 3.50, 4.00), 
                        labels = c("0 - 1.99", "2.00 - 2.49", "2.50 - 2.99", "3.00 - 3.49", "3.50 - 4.00"), 
                        include.lowest = TRUE)
  )
```

```{r}
table(predictions2$actual_bin, predictions2$predicted_bin)
```

```{r}
ggplot(predictions2, aes(x = CGPA, y = .pred)) +
  geom_point(alpha = 0.6, color = "blue") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") + 
  labs(
    title = "Predicted vs. Actual GPA",
    x = "Actual GPA",
    y = "Predicted GPA"
  ) +
  theme_minimal()
```

# Alcohol Dataset 
```{r}
P_alc <- read_csv(here::here("student-por.csv"))
head(P_alc)
```

```{r}
Alc_clean <- P_alc %>%
  mutate( School = as.factor(school),
          Sex = as.factor(sex),
          Final_Grade = G3,
          Parent_Living = as.factor(Pstatus),
          Failures = as.factor(failures),
          address = as.factor(address),
          Daily_Alc = as.factor(Dalc),
          Weekend_Alc = as.factor(Walc),
          guardian = as.factor(guardian),
          reason = as.factor(reason),
          schoolsup = as.factor(schoolsup),
          famsup = as.factor(famsup),
          paid = as.factor(paid),
          activities = as.factor(activities),
          nursery = as.factor(nursery),
          
          
    
  ) %>%
  dplyr::select( -school, -sex, -G3, -Pstatus, -failures, -Dalc, -Walc  )

head(Alc_clean)
```
```{r}
alc_rec <- recipe(Final_Grade ~ age + Weekend_Alc + absences +goout +Failures + studytime, data = Alc_clean) %>%
  step_dummy(all_nominal_predictors()) %>% 
  step_normalize(all_numeric_predictors())
```

```{r}
knn_workflow <- workflow() %>%
  add_model(knn_mod_tune) %>%
  add_recipe(alc_rec)

alc_cvs <- vfold_cv(Alc_clean, v = 5, strata = Final_Grade)
```

```{r}
knn_grid <- grid_regular(neighbors(range = c(1, 300)), levels = 20)

knn_tune_results <- tune_grid(
  knn_workflow,
  resamples = alc_cvs,
  grid = knn_grid
)
```

```{r}
knn_tune_results |> 
  collect_metrics() |>
  filter(.metric == "rmse") |>
  slice_min(mean, n = 3)

knn_tune_results |> 
  collect_metrics() |>
  filter(.metric == "rsq") |>
  slice_max(mean, n = 3)
```
```{r}
knn_mod_best <- nearest_neighbor(neighbors = 79) |>
  set_mode("regression") |> 
  set_engine("kknn")
```

```{r}
best_workflow <- workflow() |>
  add_recipe(alc_rec) |>
  add_model(knn_mod_best)

best_fit <- best_workflow |>
  fit(Alc_clean) 

best_fit |> 
  extract_fit_parsnip()
```
```{r}
predictions <- predict(best_fit, new_data = Alc_clean) %>%
  bind_cols(Alc_clean)

regression_metrics <- predictions %>%
  metrics(truth = Final_Grade, estimate = .pred)

print(regression_metrics)
```


